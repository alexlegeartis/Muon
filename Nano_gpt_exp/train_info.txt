Overriding config with config/finetune_tiniy_stories.py:
import time

out_dir = "out-tiny_stories"
eval_interval = 5
eval_iters = 40
wandb_log = False  # feel free to turn on
wandb_project = "tiny_stories"
wandb_run_name = "ft-" + str(time.time())

dataset = "tiny_stories"
init_from = "gpt2-large"  # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 200

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False

tokens per iteration will be: 32,768
Initializing from OpenAI GPT-2 weights: gpt2-large
Overriding config with config/finetune_tiniy_stories.py:
import time

out_dir = "out-tiny_stories"
eval_interval = 5
eval_iters = 40
wandb_log = False  # feel free to turn on
wandb_project = "tiny_stories"
wandb_run_name = "ft-" + str(time.time())

dataset = "tiny_stories"
init_from = "gpt2-large"  # this is the largest GPT-2 model

# only save checkpoints if the validation loss improves
always_save_checkpoint = False

# the number of examples per iter:
# 1 batch_size * 32 grad_accum * 1024 tokens = 32,768 tokens/iter
# shakespeare has 301,966 tokens, so 1 epoch ~= 9.2 iters
batch_size = 1
gradient_accumulation_steps = 32
max_iters = 200

# finetune at constant LR
learning_rate = 3e-5
decay_lr = False

tokens per iteration will be: 32,768
Initializing from OpenAI GPT-2 weights: gpt2-large
loading weights from pretrained gpt: gpt2-large
forcing vocab_size=50257, block_size=1024, bias=True
overriding dropout rate to 0.0
loading weights from pretrained gpt: gpt2-large
forcing vocab_size=50257, block_size=1024, bias=True
overriding dropout rate to 0.0
number of parameters: 772.72M
number of parameters: 772.72M
num decayed parameter tensors: 146, with 773,428,480 parameters
num non-decayed parameter tensors: 290, with 601,600 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
num decayed parameter tensors: 146, with 773,428,480 parameters
num non-decayed parameter tensors: 290, with 601,600 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
step 0: train loss 1.9504, val loss 1.9800
iter 0: loss 2.0360, time 33262.22ms, mfu -100.00%
iter 1: loss 1.8378, time 1181.37ms, mfu -100.00%
iter 2: loss 1.6788, time 1370.80ms, mfu -100.00%
iter 3: loss 1.6205, time 1365.15ms, mfu -100.00%
iter 4: loss 1.5578, time 1374.73ms, mfu -100.00%
step 5: train loss 1.6790, val loss 1.7658
saving checkpoint to out-tiny_stories
iter 5: loss 1.8428, time 15793.41ms, mfu 1.73%
iter 6: loss 1.9017, time 1369.13ms, mfu 3.55%
iter 7: loss 1.8820, time 1354.48ms, mfu 5.21%
iter 8: loss 1.4832, time 1406.87ms, mfu 6.63%
iter 9: loss 1.6994, time 1380.72ms, mfu 7.95%
step 10: train loss 1.6520, val loss 1.7132
saving checkpoint to out-tiny_stories
iter 10: loss 1.4511, time 15854.21ms, mfu 7.33%
iter 11: loss 1.4638, time 1391.47ms, mfu 8.56%
iter 12: loss 1.7569, time 1384.87ms, mfu 9.67%
iter 13: loss 1.7870, time 1373.80ms, mfu 10.70%
iter 14: loss 1.6296, time 1396.74ms, mfu 11.58%
step 15: train loss 1.5995, val loss 1.6170
saving checkpoint to out-tiny_stories
iter 15: loss 1.4376, time 16094.55ms, mfu 10.59%
iter 16: loss 1.4909, time 1388.67ms, mfu 11.50%
iter 17: loss 1.3945, time 1365.51ms, mfu 12.35%
iter 18: loss 1.4703, time 1378.19ms, mfu 13.10%
iter 19: loss 1.5896, time 1376.66ms, mfu 13.77%
step 20: train loss 1.5513, val loss 1.6330
iter 20: loss 1.4448, time 3090.24ms, mfu 13.28%
iter 21: loss 1.4572, time 1384.76ms, mfu 13.93%
iter 22: loss 1.6814, time 1374.89ms, mfu 14.52%
iter 23: loss 1.3239, time 1378.97ms, mfu 15.05%
iter 24: loss 1.3302, time 1382.03ms, mfu 15.52%
step 25: train loss 1.5305, val loss 1.6365
iter 25: loss 1.3631, time 3086.42ms, mfu 14.85%
iter 26: loss 1.4904, time 1376.18ms, mfu 15.35%
iter 27: loss 1.7653, time 1388.13ms, mfu 15.79%
iter 28: loss 1.4790, time 1376.32ms, mfu 16.19%
iter 29: loss 1.7054, time 1369.86ms, mfu 16.57%
step 30: train loss 1.5369, val loss 1.5231
saving checkpoint to out-tiny_stories
iter 30: loss 1.3500, time 15960.60ms, mfu 15.08%
iter 31: loss 1.6360, time 1389.41ms, mfu 15.54%
iter 32: loss 1.4009, time 1378.91ms, mfu 15.97%
iter 33: loss 1.7308, time 1374.87ms, mfu 16.36%
iter 34: loss 1.3471, time 1373.14ms, mfu 16.71%
step 35: train loss 1.4774, val loss 1.4998
saving checkpoint to out-tiny_stories
iter 35: loss 1.3311, time 15946.26ms, mfu 15.21%
iter 36: loss 1.2707, time 1374.66ms, mfu 15.68%
iter 37: loss 1.3037, time 1367.85ms, mfu 16.11%
iter 38: loss 1.8127, time 1382.32ms, mfu 16.47%
iter 39: loss 1.3953, time 1384.99ms, mfu 16.80%
step 40: train loss 1.5018, val loss 1.5104
iter 40: loss 1.3065, time 3093.66ms, mfu 16.00%
iter 41: loss 1.3222, time 1380.44ms, mfu 16.38%
iter 42: loss 1.7311, time 1367.78ms, mfu 16.74%
iter 43: loss 1.3523, time 1391.70ms, mfu 17.03%
iter 44: loss 1.7435, time 1367.80ms, mfu 17.32%
step 45: train loss 1.4859, val loss 1.5209
iter 45: loss 1.7011, time 3100.54ms, mfu 16.47%
iter 46: loss 1.3721, time 1393.41ms, mfu 16.79%
iter 47: loss 1.3481, time 1373.70ms, mfu 17.10%
iter 48: loss 1.3090, time 1386.69ms, mfu 17.36%
iter 49: loss 1.3106, time 1389.76ms, mfu 17.59%
step 50: train loss 1.5072, val loss 1.4825
saving checkpoint to out-tiny_stories
iter 50: loss 1.8579, time 16013.74ms, mfu 16.00%
iter 51: loss 1.6708, time 1391.97ms, mfu 16.36%
iter 52: loss 1.3432, time 1363.85ms, mfu 16.73%
iter 53: loss 1.6618, time 1361.29ms, mfu 17.06%
iter 54: loss 1.7039, time 1397.23ms, mfu 17.31%
step 55: train loss 1.5187, val loss 1.5075
iter 55: loss 1.3454, time 3083.16ms, mfu 16.47%
iter 56: loss 1.4933, time 1374.42ms, mfu 16.81%
iter 57: loss 1.4846, time 1371.58ms, mfu 17.12%
iter 58: loss 1.6051, time 1396.92ms, mfu 17.36%
iter 59: loss 1.6328, time 1381.26ms, mfu 17.60%
step 60: train loss 1.4579, val loss 1.4239
saving checkpoint to out-tiny_stories
iter 60: loss 1.5977, time 15840.89ms, mfu 16.02%
iter 61: loss 1.2968, time 1365.25ms, mfu 16.42%
iter 62: loss 1.2134, time 1384.34ms, mfu 16.75%
iter 63: loss 1.1654, time 1376.44ms, mfu 17.06%
iter 64: loss 1.7174, time 1370.61ms, mfu 17.35%
step 65: train loss 1.4910, val loss 1.5467
iter 65: loss 1.6476, time 3118.00ms, mfu 16.49%
iter 66: loss 1.4791, time 1380.35ms, mfu 16.82%
iter 67: loss 1.7914, time 1402.68ms, mfu 17.08%
iter 68: loss 1.2824, time 1374.62ms, mfu 17.36%
iter 69: loss 1.6559, time 1384.09ms, mfu 17.60%
step 70: train loss 1.4633, val loss 1.4764
iter 70: loss 1.5902, time 3103.26ms, mfu 16.72%
iter 71: loss 1.3425, time 1372.97ms, mfu 17.04%
iter 72: loss 1.3384, time 1397.87ms, mfu 17.29%
iter 73: loss 1.3186, time 1378.47ms, mfu 17.54%
iter 74: loss 1.6347, time 1403.87ms, mfu 17.73%
step 75: train loss 1.4532, val loss 1.4913
iter 75: loss 1.2514, time 3100.07ms, mfu 16.84%
iter 76: loss 1.4625, time 1373.11ms, mfu 17.15%
iter 77: loss 1.6939, time 1396.30ms, mfu 17.39%
iter 78: loss 1.3216, time 1388.14ms, mfu 17.62%
iter 79: loss 1.7095, time 1378.15ms, mfu 17.84%
step 80: train loss 1.4480, val loss 1.4236
saving checkpoint to out-tiny_stories
iter 80: loss 1.3151, time 15773.89ms, mfu 16.23%
iter 81: loss 1.6668, time 1384.57ms, mfu 16.58%
iter 82: loss 1.2669, time 1378.43ms, mfu 16.90%
iter 83: loss 1.6719, time 1367.50ms, mfu 17.21%
iter 84: loss 1.6339, time 1389.76ms, mfu 17.45%
step 85: train loss 1.4232, val loss 1.5052
iter 85: loss 1.5533, time 3101.84ms, mfu 16.59%
iter 86: loss 1.6889, time 1392.85ms, mfu 16.89%
iter 87: loss 1.6693, time 1366.36ms, mfu 17.20%
iter 88: loss 1.3008, time 1393.83ms, mfu 17.44%
iter 89: loss 1.2526, time 1392.16ms, mfu 17.66%
step 90: train loss 1.4369, val loss 1.4138
saving checkpoint to out-tiny_stories
iter 90: loss 1.7288, time 16429.23ms, mfu 16.06%
iter 91: loss 1.6434, time 1376.00ms, mfu 16.44%
iter 92: loss 1.5546, time 1381.33ms, mfu 16.77%
iter 93: loss 1.2809, time 1365.02ms, mfu 17.10%
iter 94: loss 1.7500, time 1384.14ms, mfu 17.36%
step 95: train loss 1.4204, val loss 1.4439
iter 95: loss 1.1799, time 3102.23ms, mfu 16.51%
iter 96: loss 1.3578, time 1377.86ms, mfu 16.84%
iter 97: loss 1.2736, time 1404.01ms, mfu 17.10%
iter 98: loss 1.6790, time 1378.63ms, mfu 17.37%
iter 99: loss 1.3208, time 1390.18ms, mfu 17.60%
step 100: train loss 1.4579, val loss 1.4050
saving checkpoint to out-tiny_stories
iter 100: loss 1.0714, time 16034.39ms, mfu 16.01%
iter 101: loss 1.2424, time 1381.91ms, mfu 16.39%
iter 102: loss 1.6453, time 1381.15ms, mfu 16.73%
iter 103: loss 1.2279, time 1389.61ms, mfu 17.02%
iter 104: loss 1.5576, time 1387.74ms, mfu 17.29%
step 105: train loss 1.4079, val loss 1.4082
iter 105: loss 1.2349, time 3111.80ms, mfu 16.44%
iter 106: loss 1.6971, time 1388.19ms, mfu 16.76%
iter 107: loss 1.2602, time 1368.65ms, mfu 17.08%
iter 108: loss 1.6678, time 1385.16ms, mfu 17.34%
iter 109: loss 1.1267, time 1385.59ms, mfu 17.58%
step 110: train loss 1.4706, val loss 1.4283
iter 110: loss 1.5949, time 3077.25ms, mfu 16.71%
iter 111: loss 1.3918, time 1410.34ms, mfu 16.98%
iter 112: loss 1.6431, time 1380.86ms, mfu 17.26%
iter 113: loss 1.2076, time 1393.18ms, mfu 17.49%
iter 114: loss 1.2009, time 1379.82ms, mfu 17.72%
step 115: train loss 1.3905, val loss 1.3734
saving checkpoint to out-tiny_stories
iter 115: loss 1.5188, time 16156.29ms, mfu 16.12%
iter 116: loss 1.1851, time 1375.26ms, mfu 16.50%
iter 117: loss 1.5659, time 1367.10ms, mfu 16.84%
iter 118: loss 1.3451, time 1390.18ms, mfu 17.12%
iter 119: loss 1.5737, time 1372.82ms, mfu 17.40%
step 120: train loss 1.4655, val loss 1.4129
iter 120: loss 1.7091, time 3086.28ms, mfu 16.55%
iter 121: loss 1.1647, time 1379.32ms, mfu 16.87%
iter 122: loss 1.1284, time 1397.82ms, mfu 17.14%
iter 123: loss 1.4488, time 1396.11ms, mfu 17.38%
iter 124: loss 1.5586, time 1358.41ms, mfu 17.66%
step 125: train loss 1.4734, val loss 1.4140
iter 125: loss 1.6962, time 3122.88ms, mfu 16.77%
iter 126: loss 1.5347, time 1381.46ms, mfu 17.07%
iter 127: loss 1.1872, time 1398.34ms, mfu 17.31%
iter 128: loss 1.2121, time 1378.41ms, mfu 17.56%
iter 129: loss 1.1479, time 1386.23ms, mfu 17.78%
step 130: train loss 1.4024, val loss 1.3864
iter 130: loss 1.2002, time 3093.70ms, mfu 16.88%
iter 131: loss 1.2336, time 1384.86ms, mfu 17.17%
iter 132: loss 1.6086, time 1377.86ms, mfu 17.43%
iter 133: loss 1.2099, time 1384.61ms, mfu 17.66%
iter 134: loss 1.6206, time 1389.58ms, mfu 17.86%
step 135: train loss 1.3590, val loss 1.4373
iter 135: loss 1.6699, time 3088.89ms, mfu 16.96%
iter 136: loss 1.5759, time 1390.41ms, mfu 17.23%
iter 137: loss 1.2290, time 1378.11ms, mfu 17.49%
iter 138: loss 1.3191, time 1383.90ms, mfu 17.71%
iter 139: loss 1.3221, time 1392.92ms, mfu 17.90%
step 140: train loss 1.3793, val loss 1.3690
saving checkpoint to out-tiny_stories
iter 140: loss 1.7148, time 15838.90ms, mfu 16.29%
iter 141: loss 1.1324, time 1365.81ms, mfu 16.66%
iter 142: loss 1.6395, time 1389.55ms, mfu 16.96%
iter 143: loss 1.2476, time 1400.68ms, mfu 17.21%
iter 144: loss 1.7018, time 1374.27ms, mfu 17.48%
step 145: train loss 1.4066, val loss 1.4602
iter 145: loss 1.6333, time 3111.96ms, mfu 16.61%
iter 146: loss 1.2471, time 1381.17ms, mfu 16.93%
iter 147: loss 1.1685, time 1374.26ms, mfu 17.22%
iter 148: loss 1.3274, time 1391.21ms, mfu 17.46%
iter 149: loss 1.2749, time 1381.97ms, mfu 17.69%
step 150: train loss 1.3880, val loss 1.3929
iter 150: loss 1.1444, time 3100.88ms, mfu 16.81%
iter 151: loss 1.3527, time 1386.54ms, mfu 17.10%
iter 152: loss 1.1001, time 1400.23ms, mfu 17.34%
iter 153: loss 1.6569, time 1392.32ms, mfu 17.57%
iter 154: loss 1.6955, time 1387.09ms, mfu 17.78%
step 155: train loss 1.4332, val loss 1.3677
saving checkpoint to out-tiny_stories
iter 155: loss 1.7419, time 15898.18ms, mfu 16.17%
iter 156: loss 1.1944, time 1385.42ms, mfu 16.53%
iter 157: loss 1.7516, time 1368.37ms, mfu 16.87%
iter 158: loss 1.2012, time 1390.30ms, mfu 17.15%
iter 159: loss 1.6879, time 1377.53ms, mfu 17.42%
step 160: train loss 1.3961, val loss 1.3413
saving checkpoint to out-tiny_stories
iter 160: loss 1.7104, time 15974.28ms, mfu 15.85%
iter 161: loss 1.5476, time 1383.94ms, mfu 16.24%
iter 162: loss 1.6300, time 1394.90ms, mfu 16.57%
iter 163: loss 1.6653, time 1362.99ms, mfu 16.92%
iter 164: loss 1.1828, time 1384.27ms, mfu 17.20%
step 165: train loss 1.3984, val loss 1.3953
iter 165: loss 1.0913, time 3078.35ms, mfu 16.37%
iter 166: loss 1.3029, time 1381.70ms, mfu 16.71%
iter 167: loss 1.7165, time 1380.03ms, mfu 17.02%
iter 168: loss 1.1925, time 1381.99ms, mfu 17.29%
iter 169: loss 1.5375, time 1385.77ms, mfu 17.53%
step 170: train loss 1.3754, val loss 1.4269
iter 170: loss 1.5703, time 3083.91ms, mfu 16.67%
iter 171: loss 1.7087, time 1394.42ms, mfu 16.96%
iter 172: loss 1.7382, time 1384.76ms, mfu 17.24%
iter 173: loss 1.6359, time 1375.09ms, mfu 17.50%
iter 174: loss 1.7545, time 1388.18ms, mfu 17.72%
step 175: train loss 1.3849, val loss 1.3511
iter 175: loss 1.2090, time 3114.48ms, mfu 16.82%
iter 176: loss 1.1553, time 1370.25ms, mfu 17.13%
iter 177: loss 1.1920, time 1403.20ms, mfu 17.37%
iter 178: loss 1.6194, time 1385.39ms, mfu 17.60%
iter 179: loss 1.6416, time 1389.54ms, mfu 17.81%
step 180: train loss 1.4128, val loss 1.3494
iter 180: loss 1.5551, time 3106.78ms, mfu 16.91%
iter 181: loss 1.6913, time 1397.06ms, mfu 17.17%
iter 182: loss 1.7173, time 1392.82ms, mfu 17.42%
iter 183: loss 1.6198, time 1377.59ms, mfu 17.66%
iter 184: loss 1.6617, time 1379.08ms, mfu 17.87%
step 185: train loss 1.3947, val loss 1.3500
iter 185: loss 1.3433, time 3105.78ms, mfu 16.97%
iter 186: loss 1.1203, time 1386.66ms, mfu 17.24%
iter 187: loss 1.6203, time 1382.10ms, mfu 17.49%
iter 188: loss 1.0852, time 1393.48ms, mfu 17.70%
iter 189: loss 1.6542, time 1394.77ms, mfu 17.89%
step 190: train loss 1.3882, val loss 1.3692
iter 190: loss 1.2587, time 3115.67ms, mfu 16.98%
iter 191: loss 1.1033, time 1388.63ms, mfu 17.25%
iter 192: loss 1.6122, time 1387.64ms, mfu 17.49%
iter 193: loss 1.5815, time 1378.11ms, mfu 17.73%
iter 194: loss 1.4848, time 1390.02ms, mfu 17.92%
step 195: train loss 1.3688, val loss 1.3716
iter 195: loss 1.6892, time 3104.36ms, mfu 17.01%
iter 196: loss 1.4346, time 1386.94ms, mfu 17.28%
iter 197: loss 1.1894, time 1379.95ms, mfu 17.53%
iter 198: loss 1.3127, time 1388.47ms, mfu 17.74%
iter 199: loss 1.1909, time 1393.71ms, mfu 17.93%
step 200: train loss 1.3508, val loss 1.4290
iter 200: loss 1.6673, time 3098.51ms, mfu 17.02%
